"""
æ™ºèƒ½è¯é¢‘ç»Ÿè®¡å™¨æ¡†æ¶
ä½ çš„ä»»åŠ¡ï¼šå®ç°æ‰€æœ‰æ ‡è®°ä¸º # TODO çš„æ–¹æ³•
"""

from collections import Counter, defaultdict
import re
import string
from typing import List, Tuple, Dict, Set


class SmartWordCounter:
    """æ™ºèƒ½è¯é¢‘ç»Ÿè®¡å™¨"""
    
    def __init__(self, 
                 ignore_case: bool = True,
                 ignore_punctuation: bool = True,
                 min_word_length: int = 1,
                 stop_words: Set[str] = None):
        """
        åˆå§‹åŒ–è¯é¢‘ç»Ÿè®¡å™¨
        
        Args:
            ignore_case: æ˜¯å¦å¿½ç•¥å¤§å°å†™
            ignore_punctuation: æ˜¯å¦å¿½ç•¥æ ‡ç‚¹ç¬¦å·
            min_word_length: æœ€å°è¯é•¿åº¦
            stop_words: åœç”¨è¯é›†åˆ
        """
        self.ignore_case = ignore_case
        self.ignore_punctuation = ignore_punctuation
        self.min_word_length = min_word_length
        self.stop_words = stop_words or set()
        
        # ç»Ÿè®¡æ•°æ®
        self.word_counts = Counter()
        self.total_words = 0
        self.unique_words = 0
        
        # é»˜è®¤è‹±æ–‡åœç”¨è¯
        self.default_english_stop_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have',
            'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should',
            'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those'
        }
    
    def preprocess_text(self, text: str) -> List[str]:
        """
        é¢„å¤„ç†æ–‡æœ¬ï¼Œæå–è¯æ±‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            List[str]: å¤„ç†åçš„è¯æ±‡åˆ—è¡¨
        """
        # TODO: å®ç°æ–‡æœ¬é¢„å¤„ç†
        # æç¤ºï¼š
        # 1. å¤„ç†å¤§å°å†™
        if self.ignore_case:
            text = text.lower()
        # 2. å»é™¤æ ‡ç‚¹ç¬¦å·
        if self.ignore_punctuation:
            translator = str.maketrans("","",string.punctuation)
            text = text.translate(translator)
        # 3. åˆ†å‰²æˆè¯æ±‡
        words = text.split() ## è‡ªåŠ¨å¤„ç†æ‰€æœ‰ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬\n, \tç­‰ï¼‰
        # 4. è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        filtered_words = []
        for word in words:
            # è¿‡æ»¤çŸ­è¯
            if len(word) < self.min_word_length:
                continue
            # è¿‡æ»¤åœç”¨è¯
            if word in self.stop_words:
                continue
            filtered_words.append(word)
        return filtered_words

    
    def add_text(self, text: str) -> 'SmartWordCounter':
        """
        æ·»åŠ æ–‡æœ¬è¿›è¡Œç»Ÿè®¡
        
        Args:
            text: è¦åˆ†æçš„æ–‡æœ¬
            
        Returns:
            SmartWordCounter: è¿”å›è‡ªèº«æ”¯æŒé“¾å¼è°ƒç”¨
        """
        # TODO: å®ç°æ–‡æœ¬æ·»åŠ åŠŸèƒ½
        # æç¤ºï¼š
        # 1. è°ƒç”¨ preprocess_text å¤„ç†æ–‡æœ¬
        processed_words = self.preprocess_text(text)
        # 2. æ›´æ–° word_counts
        self.word_counts.update(processed_words)
        # 3. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.total_words = sum(self.word_counts.values())
        self.unique_words = len(self.word_counts)
        return self
        
        
    
    def get_top_words(self, n: int = 10) -> List[Tuple[str, int]]:
        """
        è·å–æœ€å¸¸è§çš„ N ä¸ªè¯
        
        Args:
            n: è¿”å›çš„è¯æ±‡æ•°é‡
            
        Returns:
            List[Tuple[str, int]]: (è¯æ±‡, é¢‘æ¬¡) çš„åˆ—è¡¨
        """
        # TODO: å®ç°è·å–çƒ­é—¨è¯æ±‡
        # æç¤ºï¼šä½¿ç”¨ Counter.most_common()
        return self.word_counts.most_common(n)
    
    def get_word_frequency(self, word: str) -> int:
        """
        è·å–ç‰¹å®šè¯æ±‡çš„é¢‘æ¬¡
        
        Args:
            word: è¦æŸ¥è¯¢çš„è¯æ±‡
            
        Returns:
            int: è¯æ±‡å‡ºç°æ¬¡æ•°
        """
        # TODO: å®ç°è¯æ±‡é¢‘æ¬¡æŸ¥è¯¢
        if self.ignore_case:
            word = word.lower()
        return self.word_counts[word]
        
    
    
    def get_statistics(self) -> Dict[str, any]:
        """
        è·å–ç»Ÿè®¡åˆ†ææŠ¥å‘Š
        
        Returns:
            Dict: åŒ…å«å„ç§ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        # TODO: å®ç°ç»Ÿè®¡æŠ¥å‘Š
        # æç¤ºï¼šè®¡ç®—æ€»è¯æ•°ã€å”¯ä¸€è¯æ•°ã€å¹³å‡è¯é•¿ç­‰
        res = {}
        res["total_words"] = self.total_words
        res["unique_words"] = self.unique_words
        if self.total_words > 0:
            total_chars = sum(len(word) * count for word, count in self.word_counts.items())
            res["average_word_length"] = total_chars / self.total_words
        else:
            res["average_word_length"] = 0
        return res
        
    
    def filter_by_frequency(self, min_freq: int = 2) -> Dict[str, int]:
        """
        æŒ‰é¢‘æ¬¡è¿‡æ»¤è¯æ±‡
        
        Args:
            min_freq: æœ€å°é¢‘æ¬¡
            
        Returns:
            Dict[str, int]: è¿‡æ»¤åçš„è¯æ±‡ç»Ÿè®¡
        """
        # TODO: å®ç°é¢‘æ¬¡è¿‡æ»¤
        res = {}
        for k,v in self.word_counts.items():
            if v >= min_freq:
                res[k] = v
        return res
        

    
    def clear(self) -> 'SmartWordCounter':
        """æ¸…é™¤æ‰€æœ‰ç»Ÿè®¡æ•°æ®"""
        # TODO: å®ç°æ•°æ®æ¸…é™¤
        self.word_counts.clear()
        self.total_words = 0
        self.unique_words = 0
        return self
    
    def __str__(self) -> str:
        """è¿”å›ç»Ÿè®¡æ‘˜è¦"""
        return f"SmartWordCounter(æ€»è¯æ•°: {self.total_words}, å”¯ä¸€è¯æ•°: {self.unique_words})"


def test_word_counter():
    """æµ‹è¯•å‡½æ•° - ç”¨æ¥éªŒè¯ä½ çš„å®ç°"""
    print("=== æ™ºèƒ½è¯é¢‘ç»Ÿè®¡å™¨æµ‹è¯• ===\n")
    
    # æµ‹è¯•æ–‡æœ¬
    text1 = """
    Python is a powerful programming language. 
    Python is easy to learn and Python is widely used.
    Many developers love Python because Python is versatile.
    """
    
    text2 = """
    Machine learning is revolutionizing technology.
    Deep learning, a subset of machine learning, uses neural networks.
    Learning these technologies is essential for modern developers.
    """
    
    print("1ï¸âƒ£ åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    counter = SmartWordCounter()
    counter.add_text(text1)
    
    print(f"ç»Ÿè®¡å™¨çŠ¶æ€: {counter}")
    print(f"Top 5 è¯æ±‡: {counter.get_top_words(5)}")
    print(f"'python' å‡ºç°æ¬¡æ•°: {counter.get_word_frequency('python')}")
    print()
    
    print("2ï¸âƒ£ é“¾å¼è°ƒç”¨æµ‹è¯•")
    counter.clear().add_text(text1).add_text(text2)
    print(f"æ·»åŠ ä¸¤ä¸ªæ–‡æœ¬å: {counter}")
    print(f"Top 10 è¯æ±‡: {counter.get_top_words(10)}")
    print()
    
    print("3ï¸âƒ£ é«˜çº§åŠŸèƒ½æµ‹è¯•")
    # æµ‹è¯•åœç”¨è¯è¿‡æ»¤
    counter_with_stopwords = SmartWordCounter(
        stop_words={'is', 'a', 'to', 'and', 'of'}
    )
    counter_with_stopwords.add_text(text1)
    print(f"è¿‡æ»¤åœç”¨è¯åçš„ Top 5: {counter_with_stopwords.get_top_words(5)}")
    
    # æµ‹è¯•é¢‘æ¬¡è¿‡æ»¤
    print(f"å‡ºç°2æ¬¡ä»¥ä¸Šçš„è¯: {counter.filter_by_frequency(2)}")
    
    # ç»Ÿè®¡æŠ¥å‘Š
    print(f"ç»Ÿè®¡æŠ¥å‘Š: {counter.get_statistics()}")


if __name__ == "__main__":
    print("ğŸ¯ ä½ çš„ä»»åŠ¡ï¼š")
    print("1. å®ç°æ‰€æœ‰æ ‡è®°ä¸º # TODO çš„æ–¹æ³•")
    print("2. è¿è¡Œ test_word_counter() éªŒè¯åŠŸèƒ½")
    print("3. æ€è€ƒè¿˜èƒ½æ·»åŠ ä»€ä¹ˆæœ‰è¶£çš„åŠŸèƒ½")
    print()
    print("ğŸ’¡ å®ç°æç¤ºï¼š")
    print("- ä½¿ç”¨ Counter è¿›è¡Œè¯é¢‘ç»Ÿè®¡")
    print("- ä½¿ç”¨ re æ¨¡å—å¤„ç†æ–‡æœ¬")
    print("- æ³¨æ„é“¾å¼è°ƒç”¨è¦è¿”å› self")
    print("- è€ƒè™‘è¾¹ç•Œæƒ…å†µï¼ˆç©ºæ–‡æœ¬ã€ç‰¹æ®Šå­—ç¬¦ç­‰ï¼‰")
    print()
    
    # å–æ¶ˆæ³¨é‡Šæ¥æµ‹è¯•ä½ çš„å®ç°
    test_word_counter()